from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import openai
import os

# í™˜ê²½ ë³€ìˆ˜ì—ì„œ OpenAI API í‚¤ ë¡œë“œ
openai.api_key = os.getenv("OPENAI_API_KEY")

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# CORS ì„¤ì • (Reactì—ì„œ ìš”ì²­ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # React ì•± ì‹¤í–‰ ì£¼ì†Œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­ ë°ì´í„° ëª¨ë¸ ì •ì˜
class PresentationRequest(BaseModel):
    topic: str
    purpose: str
    summary: str
    audience: str = "ì¼ë°˜ ì²­ì¤‘"
    duration: str = "5ë¶„"
    style: str = "ì „ë¬¸ì "

def create_presentation_prompt(data: PresentationRequest) -> str:
    """ LLMì´ ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸ ìƒì„± """
    duration_minutes = int(data.duration.replace("ë¶„", "")) if "ë¶„" in data.duration else 5
    
    return f"""
    ë°œí‘œ ì •ë³´:
    - ì£¼ì œ: {data.topic}
    - ëª©ì : {data.purpose}
    - ëŒ€ìƒ: {data.audience}
    - ë°œí‘œ ì‹œê°„: {data.duration}
    - ìŠ¤íƒ€ì¼: {data.style}

    ì „ë‹¬ ë‚´ìš©:
    {data.summary}

    ìš”ì²­:
    {data.duration} ë™ì•ˆ ë°œí‘œí•  **ì¶©ë¶„í•œ ë‚´ìš©**ì„ í¬í•¨í•˜ì—¬ **ìì—°ìŠ¤ëŸ½ê³  ëª°ì…ê° ìˆëŠ” ë°œí‘œ ìŠ¤í¬ë¦½íŠ¸**ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
    ë°œí‘œ ìŠ¤í¬ë¦½íŠ¸ëŠ” **ë§¤ìš° ìƒì„¸í•˜ê³  êµ¬ì²´ì ì¸ ë‚´ìš©**ì„ í¬í•¨í•´ì•¼ í•˜ë©°, ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ ë”°ë¦…ë‹ˆë‹¤:

    **1. ë„ì…ë¶€ ({int(duration_minutes * 1.2)}ë¶„)**
        - ì²­ì¤‘ì˜ ê´€ì‹¬ì„ ëŒê¸° ìœ„í•œ ê°•ë ¬í•œ ì§ˆë¬¸, ìŠ¤í† ë¦¬, ìœ ëª…í•œ ì¸ìš©êµ¬ í™œìš©
        - ë°œí‘œì˜ ì¤‘ìš”ì„± ê°•ì¡° ë° í•µì‹¬ ë©”ì‹œì§€ ì „ë‹¬
        - ë°œí‘œì˜ ëª©ì  ë° ê¸°ëŒ€ íš¨ê³¼ ì„¤ëª…
        - **ë°°ê²½ ì •ë³´** ë° ê´€ë ¨ ë§¥ë½ ì œê³µ
        - ë°œí‘œì˜ íë¦„ ë¯¸ë¦¬ ì•ˆë‚´

    **2. ë³¸ë¡  ({int(duration_minutes * 1.6)}ë¶„)**
        - **í•µì‹¬ ë‚´ìš© ì „ê°œ (ìµœì†Œ 4~5ê°œì˜ ì£¼ìš” í¬ì¸íŠ¸)**  
        - **ê° í¬ì¸íŠ¸ì— ìµœì†Œ 4ê°œì˜ ì„¸ë¶€ ì„¤ëª… ì¶”ê°€ (í†µê³„, ì‚¬ë¡€, ì „ë¬¸ê°€ ì˜ê²¬, ë¹„ìœ  ë“± í™œìš©)**
        - **ì‹¤ì œ ì—°êµ¬ ìë£Œ, ë‰´ìŠ¤, ë„í‘œ ë“± ì°¸ê³ í•˜ì—¬ ì •ë³´ ì œê³µ**
        - ì²­ì¤‘ê³¼ì˜ ìƒí˜¸ì‘ìš© ìš”ì†Œ ì¶”ê°€ (ì§ˆë¬¸ ìœ ë„, ë¹„ìœ , ì‹¤ìŠµ ìœ ë„)
        - **ê° ì£¼ìš” í¬ì¸íŠ¸ ì‚¬ì´ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ëŠ” ë¬¸ì¥ ì¶”ê°€**

    **3. ê²°ë¡  ({int(duration_minutes * 1.2)}ë¶„)**
        - í•µì‹¬ ìš”ì  ìš”ì•½ (ìµœëŒ€ 3ë¬¸ì¥)
        - ì²­ì¤‘ì´ ê¸°ì–µí•´ì•¼ í•  ê°€ì¥ ì¤‘ìš”í•œ ë©”ì‹œì§€ ê°•ì¡°
        - ì²­ì¤‘ì—ê²Œ ì§ˆë¬¸ ë˜ì§€ê¸° ë˜ëŠ” í–‰ë™ ì´‰êµ¬
        - ë°œí‘œë¥¼ ì¸ìƒì ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•  ê°•ë ¬í•œ ë§ˆë¬´ë¦¬ ë¬¸ì¥ í¬í•¨
    """

@app.get("/")
def read_root():
    return {
        "message": "FastAPI AI server is running!",
        "status": "active",
        "version": "1.0"
    }

@app.post("/ai/predict")
async def predict(data: PresentationRequest):
    """LLMì„ í˜¸ì¶œí•˜ì—¬ ë°œí‘œ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    try:
        if not openai.api_key:
            raise HTTPException(status_code=500, detail="OpenAI API key not configured")

        prompt = create_presentation_prompt(data)

        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì²­ì¤‘ì„ ì‚¬ë¡œì¡ëŠ” ë°œí‘œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            max_tokens=3000,  # ğŸ”§ í† í° ìˆ˜ ì¦ê°€ (ë” ê¸´ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±)
            temperature=0.75,
            presence_penalty=0.6,
            frequency_penalty=0.3
        )
        
        script = response["choices"][0]["message"]["content"]
        
        return {"script": script}

    except openai.error.OpenAIError as e:
        raise HTTPException(status_code=500, detail=f"OpenAI API ì˜¤ë¥˜: {str(e)}")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ì„œë²„ ì˜¤ë¥˜: {str(e)}")

# FastAPI ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=5000)
