import os
import whisper

# FFmpeg ê²½ë¡œ ì„¤ì • (FFmpegì´ ì„¤ì¹˜ëœ ê²½ë¡œ ì¶”ê°€)
os.environ["PATH"] += os.pathsep + r"C:\Users\zordi\Desktop\ffmpeg-2025-01-20-git-504df09c34-essentials_build\bin"

# ğŸ“¥ Whisper ëª¨ë¸ ë¡œë“œ (í•œ ë²ˆë§Œ ë¡œë“œí•˜ì—¬ ì†ë„ ìµœì í™”)
print("ğŸ“¥ Whisper ëª¨ë¸ ë¡œë“œ ì¤‘... (ì²˜ìŒ í•œ ë²ˆë§Œ ë¡œë“œ)")
model = whisper.load_model("base")  # "tiny", "base", "small" ì„ íƒ ê°€ëŠ¥

def transcribe_audio(audio_path):
    """
    ì£¼ì–´ì§„ ì˜¤ë””ì˜¤ íŒŒì¼ì„ STTë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    - ëª¨ë¸ì„ ë§¤ë²ˆ ë¡œë“œí•˜ì§€ ì•Šê³  ì¬ì‚¬ìš©
    """
    print(f"ğŸ™ï¸ {audio_path} ìŒì„±ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ ì¤‘...")

    result = model.transcribe(
        audio_path,
        language="ko",  # í•œêµ­ì–´ ì§€ì •
        temperature=0,  # ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ìœ„í•´
        fp16=False,  # CPU í™˜ê²½ ìµœì í™” (True ì‚¬ìš© ì‹œ GPU ê°€ì†)
        verbose=True,  # í„°ë¯¸ë„ì— ë³€í™˜ ì§„í–‰ ìƒí™© í‘œì‹œ
    )

    # ğŸ“Œ íƒ€ì„ìŠ¤íƒ¬í”„ + ë¬¸ì¥ ì •ë¦¬
    formatted_text = ""
    for segment in result["segments"]:
        start_time = segment["start"]
        end_time = segment["end"]
        text = segment["text"]
        formatted_text += f"[{start_time:.2f} ~ {end_time:.2f}] {text}\n\n"

    # ğŸ“ ë³€í™˜ëœ í…ìŠ¤íŠ¸ ì €ì¥
    output_file = f"{audio_path}.txt"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(formatted_text)

    print(f"âœ… ë³€í™˜ ì™„ë£Œ! ê²°ê³¼ ì €ì¥: {output_file}")

# âœ… ì—¬ëŸ¬ ê°œì˜ íŒŒì¼ì„ ë³€í™˜í•  ê²½ìš°
audio_files = ["downloads/sample.mp3"]  # í•„ìš”í•˜ë©´ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ ê°€ëŠ¥
for audio in audio_files:
    transcribe_audio(audio)  # âœ… ëª¨ë¸ì„ ë‹¤ì‹œ ë¡œë“œí•˜ì§€ ì•Šê³  ë°”ë¡œ ë³€í™˜!
